{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Project Data Mosaic\n",
    "\n",
    "**Part 1 :** Electric Vehicles (EVs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 :** Data Collection Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import csv\n",
    "import os \n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reddit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_posts.csv\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"YCIS-wDpZ271OI3ZU6kzRg\",\n",
    "    client_secret=\"gKiwpWUOVcZEno2lmtqyLBafFzX-BA\",\n",
    "    user_agent=\"EVDataCollector v1.0\"\n",
    ")\n",
    "\n",
    "def fetch_reddit_posts(keyword, limit=200):\n",
    "    posts = []\n",
    "    for submission in reddit.subreddit(\"all\").search(keyword, limit=limit):\n",
    "        posts.append([\n",
    "            submission.title,\n",
    "            submission.selftext,\n",
    "            submission.author.name if submission.author else \"[deleted]\",\n",
    "            submission.created_utc,\n",
    "            submission.score,\n",
    "            submission.subreddit.display_name\n",
    "        ])\n",
    "    return posts\n",
    "\n",
    "def save_to_csv(data, filename=\"reddit_posts.csv\"):\n",
    "    headers = [\"Title\", \"Post Text\", \"Author\", \"Date\", \"Upvotes\", \"Subreddit\"]\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    keyword = [\"electric vehicle\", \"tesla\", \"ev charging\"]\n",
    "    posts_data = fetch_reddit_posts(keyword, limit=100)\n",
    "    save_to_csv(posts_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Public Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adding Kaggle credentials\n",
    "# kaggle_credentials = {\n",
    "#     \"username\": \"kashafrajpoot\",\n",
    "#     \"key\": \"3b379166602b101144ee84dce16a1af7\"\n",
    "# }\n",
    "\n",
    "\n",
    "# os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "\n",
    "\n",
    "# with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "#     json.dump(kaggle_credentials, f)\n",
    "\n",
    "# os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
    "\n",
    "# # Testing the API\n",
    "# !kaggle datasets list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Search Trends**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to google_trends_data.csv\n",
      "Saved: datasets/raw\\pytrends.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eeman\\Documents\\Assigment\\.venv\\Lib\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "keywords = [\"electric vehicle\", \"tesla\", \"ev charging\"]\n",
    "\n",
    "pytrends.build_payload(kw_list=keywords, timeframe=\"today 12-m\")\n",
    "df = pytrends.interest_over_time()\n",
    "\n",
    "if 'isPartial' in df.columns:\n",
    "    df = df.drop(columns=['isPartial'])\n",
    "    \n",
    "raw_data_dir = \"datasets/raw\"\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(raw_data_dir, \"google_trends_data.csv\")\n",
    "df.to_csv(csv_path, encoding=\"utf-8\")\n",
    "print(\"Data saved to google_trends_data.csv\")\n",
    "\n",
    "# json_data = df.reset_index().to_dict(orient=\"records\")\n",
    "json_data = df.reset_index()\n",
    "json_data['date'] = json_data['date'].astype(str)  # Convert Timestamp to string\n",
    "json_data = json_data.to_dict(orient=\"records\")\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    filepath = os.path.join(raw_data_dir, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "# google_trends_data = [df]\n",
    "save_to_json(json_data, \"pytrends.json\")\n",
    "\n",
    "# df.to_csv(\"google_trends_data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# save_to_json(google_trends_data, \"pytrends.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date       Upvotes\n",
      "count  1.000000e+02    100.000000\n",
      "mean   1.694182e+09   5086.420000\n",
      "std    4.707386e+07   7612.531735\n",
      "min    1.494662e+09      0.000000\n",
      "25%    1.665072e+09    995.000000\n",
      "50%    1.714671e+09   2176.000000\n",
      "75%    1.730871e+09   4721.000000\n",
      "max    1.739549e+09  38545.000000\n"
     ]
    }
   ],
   "source": [
    "reddit_df = pd.read_csv(\"reddit_posts.csv\")\n",
    "print(reddit_df.describe())\n",
    "# print(reddit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       electric vehicle       tesla  ev charging\n",
      "count         53.000000   53.000000         53.0\n",
      "mean           1.566038   78.037736          2.0\n",
      "std            0.500363    9.980678          0.0\n",
      "min            1.000000   64.000000          2.0\n",
      "25%            1.000000   70.000000          2.0\n",
      "50%            2.000000   75.000000          2.0\n",
      "75%            2.000000   86.000000          2.0\n",
      "max            2.000000  100.000000          2.0\n"
     ]
    }
   ],
   "source": [
    "trends_df = pd.read_csv(\"datasets/raw/google_trends_data.csv\")\n",
    "print(trends_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Technical Deliverable\n",
    "\n",
    "**In the document.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Reporting & Theoretical Questions\n",
    "\n",
    "**In the document.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
